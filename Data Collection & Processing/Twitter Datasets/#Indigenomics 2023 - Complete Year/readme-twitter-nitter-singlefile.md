
# Twitter Data Scraper

This project collects tweet information from a webpage we got from Nitter.net (thanks to Kris for the great work!). I pull out important details like who wrote the tweet, what it says, when it was posted, and some statistics. 

All the information is saved in a CSV file, making it easy to look at and understand. Because my computer isn't very powerful, I need to save each page of tweets as a separate file. However, I now have more time to work on organizing the documentation better.

## Organizing the Data

- All data is kept in a single file for easy access.
- Files are organized by year and hashtags to make it easier to read and see what still needs to be collected.

## How We Name Files

The project files are named in a way that's similar to other projects in this collection:

**Example 1:** `readme-twitter-nitter-singlefile.md`

- We put important details at the beginning (there's only one ReadMe file).
- **Followed By Additional Details:** This includes the platform name, how the data was collected, and the type of file.
- Since this way of collecting data can’t be repeated easily, it’s important to have clear names for files as we make changes.

**Example 2:** `twitter-2024-p1-9-#indigenomics-scraping-singlefile.csv`

- This includes the platform name, year, page number, total pages, hashtag used, the goal of the task, and the tool used.
- Here, less important details come later.
- We keep the most relevant information at the front to make uploading simpler.


